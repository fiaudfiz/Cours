üìù Module 5 : Le Parall√©lisme de Donn√©es (SIMD)


1. Concepts Fondamentaux

	A. La Taxonomie de Flynn
		
		C'est un syst√®me de classification des architectures d'ordinateurs (invent√© par Michael Flynn en 1966). Il classe les machines selon deux axes : le nombre de flux d'instructions et le nombre de flux de donn√©es.
    	SISD (Single Instruction, Single Data) : Le mod√®le classique "s√©quentiel". Une instruction modifie une seule donn√©e √† la fois. (Ex: c = a + b).
		SIMD (Single Instruction, Multiple Data) : Le mod√®le "vectoriel". Une seule instruction (le "chef d'orchestre") modifie plusieurs donn√©es simultan√©ment (l'orchestre).

	B. Scalaire vs Vectoriel

    Code Scalaire : C'est le code C standard. On manipule des variables unitaires (int, float, double). Une variable = Une valeur.
    Code Vectoriel : On manipule des "vecteurs". Ce ne sont pas des std::vector du C++, mais des petits tableaux de taille fixe qui rentrent pile dans un registre processeur. Une variable = Un paquet de valeurs (ex: 4 double d'un coup).

2. Architecture des Registres Vectoriels

	Localisation : Ces registres se trouvent physiquement √† l'int√©rieur du c≈ìur du processeur (Core), juste √† c√¥t√© de l'ALU (Unit√© Arithm√©tique et Logique). C'est la m√©moire la plus rapide qui existe (plus rapide que le Cache L1).
	Pour supporter le SIMD, le processeur dispose de registres d√©di√©s, beaucoup plus larges que les registres g√©n√©raux (comme RAX ou RBX qui font 64 bits) :
    	XMM (SSE - Streaming SIMD Extensions) : 128 bits.
    	YMM (AVX/AVX2 - Advanced Vector Extensions) : 256 bits.
    	ZMM (AVX-512) : 512 bits (Surtout sur les serveurs).

	Capacit√© d'un registre YMM (256 bits) :
			Rappel : 1 octet = 8 bits. Donc 256 bits = 32 octets.

    4 valeurs double (64 bits chacune) -> Id√©al pour la pr√©cision des fractales.
    8 valeurs float ou int (32 bits chacune).
    32 valeurs char (8 bits chacune).

3. Le Jeu d'Instructions (ISA Extensions)

	Le passage du code scalaire au code vectoriel n√©cessite que le CPU comprenne de nouveaux mots (Instructions Assembleur).
    SSE (Legacy) : Utilise les registres XMM. Instructions comme addps (Add Packed Single-precision).
    AVX/AVX2 (Moderne) : Utilise les registres YMM. Introduit le format VEX (les instructions commencent souvent par "v").
        Exemple : vaddpd (Vector Add Packed Double-Precision).
        Traduction : "Additionne (Add) des paquets (Packed) de nombres √† virgule flottante double pr√©cision (Double)".

4. Impl√©mentation en C : Deux Approches
	
	A. Les Intrinsics (Bas niveau)

		Ce sont des fonctions C bizarres (fournies par <immintrin.h>) qui servent de pont direct vers l'assembleur.
    	Mapper : Cela signifie qu'il y a une correspondance "1 pour 1". Quand tu √©cris la fonction C _mm256_add_pd(...), le compilateur n'a pas le choix : il doit √©crire l'instruction assembleur vaddpd dans le binaire final.
    	Inconv√©nient (Non portable) : Ces fonctions sont li√©es √† l'architecture du processeur (Intel/AMD x86). Si tu essaies de compiler ce code pour un MacBook M1/M2/M3 (Architecture ARM), √ßa plantera, car l'instruction vaddpd n'existe pas chez ARM (ils utilisent "NEON").

	B. Vector Extensions (Abstraction Compilateur)

		L'approche plus moderne et lisible (celle de GCC/Clang).
		typedef double v4d __attribute__((vector_size(32)));
    	Surcharge d'op√©rateur (Overloading) : En C standard, le signe + ne sait additionner que des nombres. Ici, le compilateur est "entra√Æn√©" pour comprendre que si on met un + entre deux vecteurs v4d, il doit g√©n√©rer l'instruction vectorielle vaddpd pour additionner les 4 √©l√©ments d'un coup.
    	Auto-vectorisation : Avec les flags -O3 -mavx2, le compilateur essaie d'√™tre intelligent. S'il voit une boucle for (i=0; i<4; i++), il peut d√©cider tout seul de la transformer en une seule instruction SIMD.

5. Le Probl√®me de la Divergence

	Dans un code scalaire (SISD), le processeur peut prendre des chemins diff√©rents pour chaque donn√©e (via des if / else).
	En SIMD, les 4 donn√©es sont "li√©es" ensemble dans le registre. Elles subissent la m√™me instruction au m√™me moment.

		Projet Fract-ol :
		Si tu calcules 4 pixels. Le pixel #1 a fini (il est sorti du cercle), mais les pixels #2, #3, #4 doivent continuer. Le processeur ne peut pas arr√™ter le calcul pour le #1 seulement.

		La Solution : Le Masquage (Masking)
		On compare tout le monde : vcmppd.
    	Cela cr√©e un Masque : un vecteur de "Vrai/Faux" binaire.
        Pixel 1 fini : 0x000... (Tout √† z√©ro).
        Pixel 2 continue : 0xFFF... (Tout √† un).

    On utilise des op√©rations logiques (AND, OR) pour "filtrer". On continue les calculs pour tout le monde, mais on n'enregistre les r√©sultats que l√† o√π le masque est √† 1.

6. Contraintes de Performance
	
	A. Alignement M√©moire

		Le CPU charge les donn√©es par blocs de 128 ou 256 bits.
    	Align√© : L'adresse m√©moire est un multiple de 32 (pour AVX). Le CPU charge le bloc en une seule traite. (vmovaps - Aligned Packed Single).
    	Non-align√© : L'adresse est "bancale". Le bloc de donn√©es peut √™tre √† cheval sur deux Cache Lines diff√©rentes. Le CPU doit faire deux lectures et recoller les morceaux. C'est plus lent. (vmovups - Unaligned).

	B. Latence vs D√©bit (Throughput)

    	Latence : Le temps qu'il faut √† une seule voiture pour traverser l'autoroute (le pipeline).
    	D√©bit (Throughput) : Le nombre de voitures qui peuvent passer en une heure.
    	Le SIMD n'am√©liore pas la latence (le calcul a+b ne va pas plus vite).
    	Le SIMD explose le d√©bit (on fait 4 calculs a+b dans le m√™me laps de temps).